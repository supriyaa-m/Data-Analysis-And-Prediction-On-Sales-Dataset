{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d4aab-b105-4919-811e-96b96e7e74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d75f292-4bdc-4a5c-b4a7-256492c1579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark SQL Read From Excel\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e876fc-28db-4c70-8af1-ed7678a6dbac",
   "metadata": {},
   "source": [
    "we can read from excel in two ways \n",
    "1. Using spark-excel library where we have to download spark-excel jar -> create a folder named spark_jars inside SPARK_HOME(env variable) path and paste the downloaded jar in this directory.\n",
    "   then -> add the jar path into spark.executor.extraClassPath using below syntax :\n",
    "   \n",
    "   spark-submit --jars myjar.jar \\ \n",
    "  --driver-class-path myjar.jar \\      # adding to driver's class path\n",
    "  \n",
    "  \n",
    "  --conf spark.executor.extraClassPath=myjar.jar \\  # adding to executor's class path\n",
    "  \n",
    "  \n",
    "  --class SampleApplication my-application.jar\n",
    "  \n",
    "  or with below syntax:\n",
    "  \n",
    "  conf = SparkConf().set(\"spark.jars\", \"/path-to-jar/jar_name.jar\")\n",
    "    \n",
    "    \n",
    "  sc = SparkContext( conf=conf)\n",
    "  \n",
    "  or\n",
    "  \n",
    "  conf.set(\"spark.executor.extraClassPath\", \"C:\\\\Users\\\\supri\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-    packages\\\\pyspark\\\\jars\\\\\")\n",
    "  \n",
    "(In short: Create directory spark_jars in the SPARK_HOME then store the spark-excel package in spark_jars directory -> Add the spark_jars to spark.executor.extraClassPath of Spark session)\n",
    "\n",
    "2. Using Python pandas read the excel and convert the dataframe to spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7df964-a4d2-40bc-a1ab-710dfee5a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|Row ID|Order ID|Order Date|Order Priority|Order Quantity|            Sales|Discount|     Ship Mode|             Profit|Unit Price|Shipping Cost|     Customer Name|Province| Region|Customer Segment|Product Category|Product Sub-Category|        Product Name|Product Container|Product Base Margin|Ship Date|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|   1.0|     3.0|   40464.0|           Low|           6.0|           261.54|    0.04|   Regular Air|            -213.25|     38.94|         35.0|Muhammed MacIntyre| Nunavut|Nunavut|  Small Business| Office Supplies|Storage & Organiz...|Eldon Base for st...|        Large Box|                0.8|  40471.0|\n",
      "|  49.0|   293.0|   41183.0|          High|          49.0|         10123.02|    0.07|Delivery Truck|             457.81|    208.16|        68.02|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|1.7 Cubic Foot Co...|       Jumbo Drum|               0.58|  41184.0|\n",
      "|  50.0|   293.0|   41183.0|          High|          27.0|           244.57|    0.01|   Regular Air|            46.7075|      8.69|         2.99|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|Binders and Binde...|Cardinal Slant-D速...|        Small Box|               0.39|  41185.0|\n",
      "|  80.0|   483.0|   40734.0|          High|          30.0|4965.759499999999|    0.08|   Regular Air|           1198.971|    195.99|         3.99|     Clay Rozendal| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                R380|        Small Box|               0.58|  40736.0|\n",
      "|  85.0|   515.0|   40418.0| Not Specified|          19.0|           394.27|    0.08|   Regular Air|              30.94|     21.78|         5.94|    Carlos Soltero| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  40420.0|\n",
      "|  86.0|   515.0|   40418.0| Not Specified|          21.0|           146.69|    0.05|   Regular Air|               4.43|      6.64|         4.95|    Carlos Soltero| Nunavut|Nunavut|        Consumer|       Furniture|  Office Furnishings|G.E. Longer-Life ...|       Small Pack|               0.37|  40420.0|\n",
      "|  97.0|   613.0|   40711.0|          High|          12.0|            93.54|    0.03|   Regular Air|           -54.0385|       7.3|         7.72|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Binders and Binde...|Angle-D Binders w...|        Small Box|               0.38|  40711.0|\n",
      "|  98.0|   613.0|   40711.0|          High|          22.0|           905.08|    0.09|   Regular Air|              127.7|     42.76|         6.22|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Mobile Desk...|        Small Box|               null|  40712.0|\n",
      "| 103.0|   643.0|   40626.0|          High|          21.0|          2781.82|    0.07|   Express Air|            -695.26|    138.14|         35.0|    Monica Federle| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Commercial ...|        Large Box|               null|  40627.0|\n",
      "| 107.0|   678.0|   40235.0|           Low|          44.0|           228.41|    0.07|   Regular Air|            -226.36|      4.98|         8.33|   Dorothy Badders| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|           Xerox 198|        Small Box|               0.38|  40235.0|\n",
      "| 127.0|   807.0|   40505.0|        Medium|          45.0|           196.85|    0.01|   Regular Air|            -166.85|      4.28|         6.18|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|          Xerox 1980|        Small Box|                0.4|  40506.0|\n",
      "| 128.0|   807.0|   40505.0|        Medium|          32.0|           124.56|    0.04|   Regular Air|             -14.33|      3.95|          2.0|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|        Rubber Bands|Advantus Map Penn...|         Wrap Bag|               0.53|  40506.0|\n",
      "| 134.0|   868.0|   41068.0| Not Specified|          32.0|           716.84|     0.0|   Regular Air|             134.72|     21.78|         5.94|       Carlos Daly| Nunavut|Nunavut|     Home Office| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  41069.0|\n",
      "| 135.0|   868.0|   41068.0| Not Specified|          31.0|          1474.33|    0.04|   Regular Air|             114.46|     47.98|         3.61|       Carlos Daly| Nunavut|Nunavut|     Home Office|      Technology|Computer Peripherals|DS/HD IBM Formatt...|       Small Pack|               0.71|  41070.0|\n",
      "| 149.0|   933.0|   41125.0| Not Specified|          15.0|            80.61|    0.02|   Regular Air|             -4.715|      5.28|         2.99|     Claudia Miner| Nunavut|Nunavut|  Small Business| Office Supplies|Binders and Binde...|Wilson Jones 1\" H...|        Small Box|               0.37|  41125.0|\n",
      "| 160.0|   995.0|   40693.0|        Medium|          46.0|          1815.49|    0.03|   Regular Air|             782.91|     39.89|         3.04|   Neola Schneider| Nunavut|Nunavut|     Home Office|       Furniture|  Office Furnishings|Ultra Commercial ...|         Wrap Bag|               0.53|  40694.0|\n",
      "| 161.0|   998.0|   40142.0| Not Specified|          16.0|           248.26|    0.07|   Regular Air|               93.8|     15.74|         1.39|  Allen Rosenblatt| Nunavut|Nunavut|  Small Business| Office Supplies|           Envelopes|#10-4 1/8\" x 9 1/...|        Small Box|                0.4|  40143.0|\n",
      "| 175.0|  1154.0|   40953.0|      Critical|          44.0|          4462.23|    0.04|Delivery Truck|             440.72|    100.98|        26.22|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|           Bookcases|Hon 4-Shelf Metal...|        Jumbo Box|                0.6|  40955.0|\n",
      "| 176.0|  1154.0|   40953.0|      Critical|          11.0|663.7840000000001|    0.25|   Regular Air|           -481.041|     71.37|         69.0|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|              Tables|Lesro Sheffield C...|        Large Box|               0.68|  40955.0|\n",
      "| 203.0|  1344.0|   41014.0|           Low|          15.0|          834.904|    0.06|   Regular Air|-11.681999999999999|     65.99|         5.26|       Jim Radford| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                g520|        Small Box|               0.59|  41021.0|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark-excel \n",
    "# Define the file path and options\n",
    "file_path = \"C:/Supriyaa-spark-notes/Superstore_Sales.xls\"\n",
    "options = {\n",
    "    \"sheetName\": \"Sheet1\",\n",
    "    \"Header\": \"true\",\n",
    "    \"treatEmptyValuesAsNulls\": \"true\",\n",
    "    \"inferSchema\": \"true\"\n",
    "}\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "    .options(**options) \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2571bbc4-4997-484d-879b-cfae67e5dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "|Row ID|Order ID|         Order Date|Order Priority|Order Quantity|            Sales|Discount|     Ship Mode|             Profit|Unit Price|Shipping Cost|     Customer Name|Province| Region|Customer Segment|Product Category|Product Sub-Category|        Product Name|Product Container|Product Base Margin|          Ship Date|\n",
      "+------+--------+-------------------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "|     1|       3|2010-10-13 00:00:00|           Low|             6|           261.54|    0.04|   Regular Air|            -213.25|     38.94|         35.0|Muhammed MacIntyre| Nunavut|Nunavut|  Small Business| Office Supplies|Storage & Organiz...|Eldon Base for st...|        Large Box|                0.8|2010-10-20 00:00:00|\n",
      "|    49|     293|2012-10-01 00:00:00|          High|            49|         10123.02|    0.07|Delivery Truck|             457.81|    208.16|        68.02|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|1.7 Cubic Foot Co...|       Jumbo Drum|               0.58|2012-10-02 00:00:00|\n",
      "|    50|     293|2012-10-01 00:00:00|          High|            27|           244.57|    0.01|   Regular Air|            46.7075|      8.69|         2.99|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|Binders and Binde...|Cardinal Slant-D速...|        Small Box|               0.39|2012-10-03 00:00:00|\n",
      "|    80|     483|2011-07-10 00:00:00|          High|            30|4965.759499999999|    0.08|   Regular Air|           1198.971|    195.99|         3.99|     Clay Rozendal| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                R380|        Small Box|               0.58|2011-07-12 00:00:00|\n",
      "|    85|     515|2010-08-28 00:00:00| Not Specified|            19|           394.27|    0.08|   Regular Air|              30.94|     21.78|         5.94|    Carlos Soltero| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|2010-08-30 00:00:00|\n",
      "|    86|     515|2010-08-28 00:00:00| Not Specified|            21|           146.69|    0.05|   Regular Air|               4.43|      6.64|         4.95|    Carlos Soltero| Nunavut|Nunavut|        Consumer|       Furniture|  Office Furnishings|G.E. Longer-Life ...|       Small Pack|               0.37|2010-08-30 00:00:00|\n",
      "|    97|     613|2011-06-17 00:00:00|          High|            12|            93.54|    0.03|   Regular Air|           -54.0385|       7.3|         7.72|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Binders and Binde...|Angle-D Binders w...|        Small Box|               0.38|2011-06-17 00:00:00|\n",
      "|    98|     613|2011-06-17 00:00:00|          High|            22|           905.08|    0.09|   Regular Air|              127.7|     42.76|         6.22|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Mobile Desk...|        Small Box|                NaN|2011-06-18 00:00:00|\n",
      "|   103|     643|2011-03-24 00:00:00|          High|            21|          2781.82|    0.07|   Express Air|            -695.26|    138.14|         35.0|    Monica Federle| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Commercial ...|        Large Box|                NaN|2011-03-25 00:00:00|\n",
      "|   107|     678|2010-02-26 00:00:00|           Low|            44|           228.41|    0.07|   Regular Air|            -226.36|      4.98|         8.33|   Dorothy Badders| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|           Xerox 198|        Small Box|               0.38|2010-02-26 00:00:00|\n",
      "|   127|     807|2010-11-23 00:00:00|        Medium|            45|           196.85|    0.01|   Regular Air|            -166.85|      4.28|         6.18|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|          Xerox 1980|        Small Box|                0.4|2010-11-24 00:00:00|\n",
      "|   128|     807|2010-11-23 00:00:00|        Medium|            32|           124.56|    0.04|   Regular Air|             -14.33|      3.95|          2.0|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|        Rubber Bands|Advantus Map Penn...|         Wrap Bag|               0.53|2010-11-24 00:00:00|\n",
      "|   134|     868|2012-06-08 00:00:00| Not Specified|            32|           716.84|     0.0|   Regular Air|             134.72|     21.78|         5.94|       Carlos Daly| Nunavut|Nunavut|     Home Office| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|2012-06-09 00:00:00|\n",
      "|   135|     868|2012-06-08 00:00:00| Not Specified|            31|          1474.33|    0.04|   Regular Air|             114.46|     47.98|         3.61|       Carlos Daly| Nunavut|Nunavut|     Home Office|      Technology|Computer Peripherals|DS/HD IBM Formatt...|       Small Pack|               0.71|2012-06-10 00:00:00|\n",
      "|   149|     933|2012-08-04 00:00:00| Not Specified|            15|            80.61|    0.02|   Regular Air|             -4.715|      5.28|         2.99|     Claudia Miner| Nunavut|Nunavut|  Small Business| Office Supplies|Binders and Binde...|Wilson Jones 1\" H...|        Small Box|               0.37|2012-08-04 00:00:00|\n",
      "|   160|     995|2011-05-30 00:00:00|        Medium|            46|          1815.49|    0.03|   Regular Air|             782.91|     39.89|         3.04|   Neola Schneider| Nunavut|Nunavut|     Home Office|       Furniture|  Office Furnishings|Ultra Commercial ...|         Wrap Bag|               0.53|2011-05-31 00:00:00|\n",
      "|   161|     998|2009-11-25 00:00:00| Not Specified|            16|           248.26|    0.07|   Regular Air|               93.8|     15.74|         1.39|  Allen Rosenblatt| Nunavut|Nunavut|  Small Business| Office Supplies|           Envelopes|#10-4 1/8\" x 9 1/...|        Small Box|                0.4|2009-11-26 00:00:00|\n",
      "|   175|    1154|2012-02-14 00:00:00|      Critical|            44|          4462.23|    0.04|Delivery Truck|             440.72|    100.98|        26.22|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|           Bookcases|Hon 4-Shelf Metal...|        Jumbo Box|                0.6|2012-02-16 00:00:00|\n",
      "|   176|    1154|2012-02-14 00:00:00|      Critical|            11|663.7840000000001|    0.25|   Regular Air|           -481.041|     71.37|         69.0|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|              Tables|Lesro Sheffield C...|        Large Box|               0.68|2012-02-16 00:00:00|\n",
      "|   203|    1344|2012-04-15 00:00:00|           Low|            15|          834.904|    0.06|   Regular Air|-11.681999999999999|     65.99|         5.26|       Jim Radford| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                g520|        Small Box|               0.59|2012-04-22 00:00:00|\n",
      "+------+--------+-------------------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Python pandas\n",
    "pandas_df = pd.read_excel(\"C:/Supriyaa-spark-notes/Superstore_Sales.xls\")\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ea4421-6540-49fe-a88a-a4bdbe5a1169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Row ID: double (nullable = true)\n",
      " |-- Order ID: double (nullable = true)\n",
      " |-- Order Date: double (nullable = true)\n",
      " |-- Order Priority: string (nullable = true)\n",
      " |-- Order Quantity: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Ship Mode: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Unit Price: double (nullable = true)\n",
      " |-- Shipping Cost: double (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer Segment: string (nullable = true)\n",
      " |-- Product Category: string (nullable = true)\n",
      " |-- Product Sub-Category: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Product Container: string (nullable = true)\n",
      " |-- Product Base Margin: double (nullable = true)\n",
      " |-- Ship Date: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b63cf4b9-684d-45f2-a51f-b88d1101eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Row ID',\n",
       " 'Order ID',\n",
       " 'Order Date',\n",
       " 'Order Priority',\n",
       " 'Order Quantity',\n",
       " 'Sales',\n",
       " 'Discount',\n",
       " 'Ship Mode',\n",
       " 'Profit',\n",
       " 'Unit Price',\n",
       " 'Shipping Cost',\n",
       " 'Customer Name',\n",
       " 'Province',\n",
       " 'Region',\n",
       " 'Customer Segment',\n",
       " 'Product Category',\n",
       " 'Product Sub-Category',\n",
       " 'Product Name',\n",
       " 'Product Container',\n",
       " 'Product Base Margin',\n",
       " 'Ship Date']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1310e24-095d-4d08-96b0-428097e143e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Row ID: string, Order ID: string, Order Date: string, Order Priority: string, Order Quantity: string, Sales: string, Discount: string, Ship Mode: string, Profit: string, Unit Price: string, Shipping Cost: string, Customer Name: string, Province: string, Region: string, Customer Segment: string, Product Category: string, Product Sub-Category: string, Product Name: string, Product Container: string, Product Base Margin: string, Ship Date: string]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas_df.describe()\n",
    "#spark_df.describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00364b45-8dfb-49c0-b0b7-be8952ee0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType,IntegerType,StructField,StructType\n",
    "data_schema = [StructField('row ID',IntegerType(),True),\n",
    "              StructField('Order Priority',StringType(),True)]\n",
    "final_struct = StructType(fields=data_schema)\n",
    "options = {\n",
    "    \"sheetName\": \"Sheet1\",\n",
    "    \"Header\": \"true\",\n",
    "    \"treatEmptyValuesAsNulls\": \"true\",\n",
    "    \"inferSchema\": \"true\"\n",
    "}\n",
    "df1 = spark.read.format(\"com.crealytics.spark.excel\").options(**options).load(\"C:/Supriyaa-spark-notes/Superstore_Sales.xls\",schema=final_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41bca632-580e-447e-ac73-b3975d9e5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- row ID: integer (nullable = true)\n",
      " |-- Order Priority: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbf188e1-2c92-41e5-9960-1d0b028f0ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Order Priority'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Order Priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d00c7de-c0bf-4b16-86b8-4cbc30b28648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1['Order Priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e134daaf-0fe5-48c4-b5fa-b0ed07c25986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Order Priority|\n",
      "+--------------+\n",
      "|           Low|\n",
      "|          High|\n",
      "|          High|\n",
      "|          High|\n",
      "| Not Specified|\n",
      "| Not Specified|\n",
      "|          High|\n",
      "|          High|\n",
      "|          High|\n",
      "|           Low|\n",
      "|        Medium|\n",
      "|        Medium|\n",
      "| Not Specified|\n",
      "| Not Specified|\n",
      "| Not Specified|\n",
      "|        Medium|\n",
      "| Not Specified|\n",
      "|      Critical|\n",
      "|      Critical|\n",
      "|           Low|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Order Priority').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5aa637c8-e840-4255-b350-900af313c60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Row ID=1.0, Order ID=3.0, Order Date=40464.0, Order Priority='Low', Order Quantity=6.0, Sales=261.54, Discount=0.04, Ship Mode='Regular Air', Profit=-213.25, Unit Price=38.94, Shipping Cost=35.0, Customer Name='Muhammed MacIntyre', Province='Nunavut', Region='Nunavut', Customer Segment='Small Business', Product Category='Office Supplies', Product Sub-Category='Storage & Organization', Product Name='Eldon Base for stackable storage shelf, platinum', Product Container='Large Box', Product Base Margin=0.8, Ship Date=40471.0),\n",
       " Row(Row ID=49.0, Order ID=293.0, Order Date=41183.0, Order Priority='High', Order Quantity=49.0, Sales=10123.02, Discount=0.07, Ship Mode='Delivery Truck', Profit=457.81, Unit Price=208.16, Shipping Cost=68.02, Customer Name='Barry French', Province='Nunavut', Region='Nunavut', Customer Segment='Consumer', Product Category='Office Supplies', Product Sub-Category='Appliances', Product Name='1.7 Cubic Foot Compact \"Cube\" Office Refrigerators', Product Container='Jumbo Drum', Product Base Margin=0.58, Ship Date=41184.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)   # df.head(2) gives two rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0dfbff85-4946-4013-bc71-75340c7008c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Row ID=1.0, Order ID=3.0, Order Date=40464.0, Order Priority='Low', Order Quantity=6.0, Sales=261.54, Discount=0.04, Ship Mode='Regular Air', Profit=-213.25, Unit Price=38.94, Shipping Cost=35.0, Customer Name='Muhammed MacIntyre', Province='Nunavut', Region='Nunavut', Customer Segment='Small Business', Product Category='Office Supplies', Product Sub-Category='Storage & Organization', Product Name='Eldon Base for stackable storage shelf, platinum', Product Container='Large Box', Product Base Margin=0.8, Ship Date=40471.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)[0]  #Out of two rows gives 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "711c4845-5e41-4951-89af-6b2027b35d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('Row ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9e365ef-03da-44b9-8cc4-22136fbb7d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fdd286-3509-4f85-b8d2-2955f806c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|Row ID|Order Priority|\n",
      "+------+--------------+\n",
      "|   1.0|           Low|\n",
      "|  49.0|          High|\n",
      "|  50.0|          High|\n",
      "|  80.0|          High|\n",
      "|  85.0| Not Specified|\n",
      "|  86.0| Not Specified|\n",
      "|  97.0|          High|\n",
      "|  98.0|          High|\n",
      "| 103.0|          High|\n",
      "| 107.0|           Low|\n",
      "| 127.0|        Medium|\n",
      "| 128.0|        Medium|\n",
      "| 134.0| Not Specified|\n",
      "| 135.0| Not Specified|\n",
      "| 149.0| Not Specified|\n",
      "| 160.0|        Medium|\n",
      "| 161.0| Not Specified|\n",
      "| 175.0|      Critical|\n",
      "| 176.0|      Critical|\n",
      "| 203.0|           Low|\n",
      "+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Row ID','Order Priority']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e691fe-c955-4050-8fb0-593de9f5cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+------------+\n",
      "|Row ID|Order ID|Order Date|Order Priority|Order Quantity|            Sales|Discount|     Ship Mode|             Profit|Unit Price|Shipping Cost|     Customer Name|Province| Region|Customer Segment|Product Category|Product Sub-Category|        Product Name|Product Container|Product Base Margin|Ship Date|double_rowid|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+------------+\n",
      "|   1.0|     3.0|   40464.0|           Low|           6.0|           261.54|    0.04|   Regular Air|            -213.25|     38.94|         35.0|Muhammed MacIntyre| Nunavut|Nunavut|  Small Business| Office Supplies|Storage & Organiz...|Eldon Base for st...|        Large Box|                0.8|  40471.0|         2.0|\n",
      "|  49.0|   293.0|   41183.0|          High|          49.0|         10123.02|    0.07|Delivery Truck|             457.81|    208.16|        68.02|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|1.7 Cubic Foot Co...|       Jumbo Drum|               0.58|  41184.0|        98.0|\n",
      "|  50.0|   293.0|   41183.0|          High|          27.0|           244.57|    0.01|   Regular Air|            46.7075|      8.69|         2.99|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|Binders and Binde...|Cardinal Slant-D速...|        Small Box|               0.39|  41185.0|       100.0|\n",
      "|  80.0|   483.0|   40734.0|          High|          30.0|4965.759499999999|    0.08|   Regular Air|           1198.971|    195.99|         3.99|     Clay Rozendal| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                R380|        Small Box|               0.58|  40736.0|       160.0|\n",
      "|  85.0|   515.0|   40418.0| Not Specified|          19.0|           394.27|    0.08|   Regular Air|              30.94|     21.78|         5.94|    Carlos Soltero| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  40420.0|       170.0|\n",
      "|  86.0|   515.0|   40418.0| Not Specified|          21.0|           146.69|    0.05|   Regular Air|               4.43|      6.64|         4.95|    Carlos Soltero| Nunavut|Nunavut|        Consumer|       Furniture|  Office Furnishings|G.E. Longer-Life ...|       Small Pack|               0.37|  40420.0|       172.0|\n",
      "|  97.0|   613.0|   40711.0|          High|          12.0|            93.54|    0.03|   Regular Air|           -54.0385|       7.3|         7.72|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Binders and Binde...|Angle-D Binders w...|        Small Box|               0.38|  40711.0|       194.0|\n",
      "|  98.0|   613.0|   40711.0|          High|          22.0|           905.08|    0.09|   Regular Air|              127.7|     42.76|         6.22|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Mobile Desk...|        Small Box|               null|  40712.0|       196.0|\n",
      "| 103.0|   643.0|   40626.0|          High|          21.0|          2781.82|    0.07|   Express Air|            -695.26|    138.14|         35.0|    Monica Federle| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Commercial ...|        Large Box|               null|  40627.0|       206.0|\n",
      "| 107.0|   678.0|   40235.0|           Low|          44.0|           228.41|    0.07|   Regular Air|            -226.36|      4.98|         8.33|   Dorothy Badders| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|           Xerox 198|        Small Box|               0.38|  40235.0|       214.0|\n",
      "| 127.0|   807.0|   40505.0|        Medium|          45.0|           196.85|    0.01|   Regular Air|            -166.85|      4.28|         6.18|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|          Xerox 1980|        Small Box|                0.4|  40506.0|       254.0|\n",
      "| 128.0|   807.0|   40505.0|        Medium|          32.0|           124.56|    0.04|   Regular Air|             -14.33|      3.95|          2.0|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|        Rubber Bands|Advantus Map Penn...|         Wrap Bag|               0.53|  40506.0|       256.0|\n",
      "| 134.0|   868.0|   41068.0| Not Specified|          32.0|           716.84|     0.0|   Regular Air|             134.72|     21.78|         5.94|       Carlos Daly| Nunavut|Nunavut|     Home Office| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  41069.0|       268.0|\n",
      "| 135.0|   868.0|   41068.0| Not Specified|          31.0|          1474.33|    0.04|   Regular Air|             114.46|     47.98|         3.61|       Carlos Daly| Nunavut|Nunavut|     Home Office|      Technology|Computer Peripherals|DS/HD IBM Formatt...|       Small Pack|               0.71|  41070.0|       270.0|\n",
      "| 149.0|   933.0|   41125.0| Not Specified|          15.0|            80.61|    0.02|   Regular Air|             -4.715|      5.28|         2.99|     Claudia Miner| Nunavut|Nunavut|  Small Business| Office Supplies|Binders and Binde...|Wilson Jones 1\" H...|        Small Box|               0.37|  41125.0|       298.0|\n",
      "| 160.0|   995.0|   40693.0|        Medium|          46.0|          1815.49|    0.03|   Regular Air|             782.91|     39.89|         3.04|   Neola Schneider| Nunavut|Nunavut|     Home Office|       Furniture|  Office Furnishings|Ultra Commercial ...|         Wrap Bag|               0.53|  40694.0|       320.0|\n",
      "| 161.0|   998.0|   40142.0| Not Specified|          16.0|           248.26|    0.07|   Regular Air|               93.8|     15.74|         1.39|  Allen Rosenblatt| Nunavut|Nunavut|  Small Business| Office Supplies|           Envelopes|#10-4 1/8\" x 9 1/...|        Small Box|                0.4|  40143.0|       322.0|\n",
      "| 175.0|  1154.0|   40953.0|      Critical|          44.0|          4462.23|    0.04|Delivery Truck|             440.72|    100.98|        26.22|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|           Bookcases|Hon 4-Shelf Metal...|        Jumbo Box|                0.6|  40955.0|       350.0|\n",
      "| 176.0|  1154.0|   40953.0|      Critical|          11.0|663.7840000000001|    0.25|   Regular Air|           -481.041|     71.37|         69.0|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|              Tables|Lesro Sheffield C...|        Large Box|               0.68|  40955.0|       352.0|\n",
      "| 203.0|  1344.0|   41014.0|           Low|          15.0|          834.904|    0.06|   Regular Air|-11.681999999999999|     65.99|         5.26|       Jim Radford| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                g520|        Small Box|               0.59|  41021.0|       406.0|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('double_rowid',df['Row ID']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f615763-6e30-4da5-8f8e-f3c26f534599",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'double_rowid' given input columns: [Customer Name, Customer Segment, Discount, Order Date, Order ID, Order Priority, Order Quantity, Product Base Margin, Product Category, Product Container, Product Name, Product Sub-Category, Profit, Province, Region, Row ID, Sales, Ship Date, Ship Mode, Shipping Cost, Unit Price];\n'Project [Row ID#0, 'double_rowid]\n+- Relation [Row ID#0,Order ID#1,Order Date#2,Order Priority#3,Order Quantity#4,Sales#5,Discount#6,Ship Mode#7,Profit#8,Unit Price#9,Shipping Cost#10,Customer Name#11,Province#12,Region#13,Customer Segment#14,Product Category#15,Product Sub-Category#16,Product Name#17,Product Container#18,Product Base Margin#19,Ship Date#20] ExcelRelation(com.crealytics.spark.excel.CellRangeAddressDataLocator@660238c9,true,true,false,true,false,false,None,None,10,com.crealytics.spark.excel.DefaultWorkbookReader@63c44ce3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_68576\\521400213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Row ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'double_rowid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Alice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Bob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m         \"\"\"\n\u001b[1;32m-> 1685\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve 'double_rowid' given input columns: [Customer Name, Customer Segment, Discount, Order Date, Order ID, Order Priority, Order Quantity, Product Base Margin, Product Category, Product Container, Product Name, Product Sub-Category, Profit, Province, Region, Row ID, Sales, Ship Date, Ship Mode, Shipping Cost, Unit Price];\n'Project [Row ID#0, 'double_rowid]\n+- Relation [Row ID#0,Order ID#1,Order Date#2,Order Priority#3,Order Quantity#4,Sales#5,Discount#6,Ship Mode#7,Profit#8,Unit Price#9,Shipping Cost#10,Customer Name#11,Province#12,Region#13,Customer Segment#14,Product Category#15,Product Sub-Category#16,Product Name#17,Product Container#18,Product Base Margin#19,Ship Date#20] ExcelRelation(com.crealytics.spark.excel.CellRangeAddressDataLocator@660238c9,true,true,false,true,false,false,None,None,10,com.crealytics.spark.excel.DefaultWorkbookReader@63c44ce3)\n"
     ]
    }
   ],
   "source": [
    "df.select(['Row ID','double_rowid']).show()  # error as the above operation withColumn() was not an inplace operation so column double_rowid is not present in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aaf91e8-a78d-45df-ab40-3acf5da14c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|new_rowid|Order ID|Order Date|Order Priority|Order Quantity|            Sales|Discount|     Ship Mode|             Profit|Unit Price|Shipping Cost|     Customer Name|Province| Region|Customer Segment|Product Category|Product Sub-Category|        Product Name|Product Container|Product Base Margin|Ship Date|\n",
      "+---------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|      1.0|     3.0|   40464.0|           Low|           6.0|           261.54|    0.04|   Regular Air|            -213.25|     38.94|         35.0|Muhammed MacIntyre| Nunavut|Nunavut|  Small Business| Office Supplies|Storage & Organiz...|Eldon Base for st...|        Large Box|                0.8|  40471.0|\n",
      "|     49.0|   293.0|   41183.0|          High|          49.0|         10123.02|    0.07|Delivery Truck|             457.81|    208.16|        68.02|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|1.7 Cubic Foot Co...|       Jumbo Drum|               0.58|  41184.0|\n",
      "|     50.0|   293.0|   41183.0|          High|          27.0|           244.57|    0.01|   Regular Air|            46.7075|      8.69|         2.99|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|Binders and Binde...|Cardinal Slant-D速...|        Small Box|               0.39|  41185.0|\n",
      "|     80.0|   483.0|   40734.0|          High|          30.0|4965.759499999999|    0.08|   Regular Air|           1198.971|    195.99|         3.99|     Clay Rozendal| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                R380|        Small Box|               0.58|  40736.0|\n",
      "|     85.0|   515.0|   40418.0| Not Specified|          19.0|           394.27|    0.08|   Regular Air|              30.94|     21.78|         5.94|    Carlos Soltero| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  40420.0|\n",
      "|     86.0|   515.0|   40418.0| Not Specified|          21.0|           146.69|    0.05|   Regular Air|               4.43|      6.64|         4.95|    Carlos Soltero| Nunavut|Nunavut|        Consumer|       Furniture|  Office Furnishings|G.E. Longer-Life ...|       Small Pack|               0.37|  40420.0|\n",
      "|     97.0|   613.0|   40711.0|          High|          12.0|            93.54|    0.03|   Regular Air|           -54.0385|       7.3|         7.72|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Binders and Binde...|Angle-D Binders w...|        Small Box|               0.38|  40711.0|\n",
      "|     98.0|   613.0|   40711.0|          High|          22.0|           905.08|    0.09|   Regular Air|              127.7|     42.76|         6.22|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Mobile Desk...|        Small Box|               null|  40712.0|\n",
      "|    103.0|   643.0|   40626.0|          High|          21.0|          2781.82|    0.07|   Express Air|            -695.26|    138.14|         35.0|    Monica Federle| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Commercial ...|        Large Box|               null|  40627.0|\n",
      "|    107.0|   678.0|   40235.0|           Low|          44.0|           228.41|    0.07|   Regular Air|            -226.36|      4.98|         8.33|   Dorothy Badders| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|           Xerox 198|        Small Box|               0.38|  40235.0|\n",
      "|    127.0|   807.0|   40505.0|        Medium|          45.0|           196.85|    0.01|   Regular Air|            -166.85|      4.28|         6.18|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|          Xerox 1980|        Small Box|                0.4|  40506.0|\n",
      "|    128.0|   807.0|   40505.0|        Medium|          32.0|           124.56|    0.04|   Regular Air|             -14.33|      3.95|          2.0|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|        Rubber Bands|Advantus Map Penn...|         Wrap Bag|               0.53|  40506.0|\n",
      "|    134.0|   868.0|   41068.0| Not Specified|          32.0|           716.84|     0.0|   Regular Air|             134.72|     21.78|         5.94|       Carlos Daly| Nunavut|Nunavut|     Home Office| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  41069.0|\n",
      "|    135.0|   868.0|   41068.0| Not Specified|          31.0|          1474.33|    0.04|   Regular Air|             114.46|     47.98|         3.61|       Carlos Daly| Nunavut|Nunavut|     Home Office|      Technology|Computer Peripherals|DS/HD IBM Formatt...|       Small Pack|               0.71|  41070.0|\n",
      "|    149.0|   933.0|   41125.0| Not Specified|          15.0|            80.61|    0.02|   Regular Air|             -4.715|      5.28|         2.99|     Claudia Miner| Nunavut|Nunavut|  Small Business| Office Supplies|Binders and Binde...|Wilson Jones 1\" H...|        Small Box|               0.37|  41125.0|\n",
      "|    160.0|   995.0|   40693.0|        Medium|          46.0|          1815.49|    0.03|   Regular Air|             782.91|     39.89|         3.04|   Neola Schneider| Nunavut|Nunavut|     Home Office|       Furniture|  Office Furnishings|Ultra Commercial ...|         Wrap Bag|               0.53|  40694.0|\n",
      "|    161.0|   998.0|   40142.0| Not Specified|          16.0|           248.26|    0.07|   Regular Air|               93.8|     15.74|         1.39|  Allen Rosenblatt| Nunavut|Nunavut|  Small Business| Office Supplies|           Envelopes|#10-4 1/8\" x 9 1/...|        Small Box|                0.4|  40143.0|\n",
      "|    175.0|  1154.0|   40953.0|      Critical|          44.0|          4462.23|    0.04|Delivery Truck|             440.72|    100.98|        26.22|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|           Bookcases|Hon 4-Shelf Metal...|        Jumbo Box|                0.6|  40955.0|\n",
      "|    176.0|  1154.0|   40953.0|      Critical|          11.0|663.7840000000001|    0.25|   Regular Air|           -481.041|     71.37|         69.0|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|              Tables|Lesro Sheffield C...|        Large Box|               0.68|  40955.0|\n",
      "|    203.0|  1344.0|   41014.0|           Low|          15.0|          834.904|    0.06|   Regular Air|-11.681999999999999|     65.99|         5.26|       Jim Radford| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                g520|        Small Box|               0.59|  41021.0|\n",
      "+---------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('Row ID','new_rowid').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192cdb20-806b-47d5-8d1b-5ffa9499e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|Row ID|Order ID|Order Date|Order Priority|Order Quantity|            Sales|Discount|     Ship Mode|             Profit|Unit Price|Shipping Cost|     Customer Name|Province| Region|Customer Segment|Product Category|Product Sub-Category|        Product Name|Product Container|Product Base Margin|Ship Date|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "|   1.0|     3.0|   40464.0|           Low|           6.0|           261.54|    0.04|   Regular Air|            -213.25|     38.94|         35.0|Muhammed MacIntyre| Nunavut|Nunavut|  Small Business| Office Supplies|Storage & Organiz...|Eldon Base for st...|        Large Box|                0.8|  40471.0|\n",
      "|  49.0|   293.0|   41183.0|          High|          49.0|         10123.02|    0.07|Delivery Truck|             457.81|    208.16|        68.02|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|1.7 Cubic Foot Co...|       Jumbo Drum|               0.58|  41184.0|\n",
      "|  50.0|   293.0|   41183.0|          High|          27.0|           244.57|    0.01|   Regular Air|            46.7075|      8.69|         2.99|      Barry French| Nunavut|Nunavut|        Consumer| Office Supplies|Binders and Binde...|Cardinal Slant-D速...|        Small Box|               0.39|  41185.0|\n",
      "|  80.0|   483.0|   40734.0|          High|          30.0|4965.759499999999|    0.08|   Regular Air|           1198.971|    195.99|         3.99|     Clay Rozendal| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                R380|        Small Box|               0.58|  40736.0|\n",
      "|  85.0|   515.0|   40418.0| Not Specified|          19.0|           394.27|    0.08|   Regular Air|              30.94|     21.78|         5.94|    Carlos Soltero| Nunavut|Nunavut|        Consumer| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  40420.0|\n",
      "|  86.0|   515.0|   40418.0| Not Specified|          21.0|           146.69|    0.05|   Regular Air|               4.43|      6.64|         4.95|    Carlos Soltero| Nunavut|Nunavut|        Consumer|       Furniture|  Office Furnishings|G.E. Longer-Life ...|       Small Pack|               0.37|  40420.0|\n",
      "|  97.0|   613.0|   40711.0|          High|          12.0|            93.54|    0.03|   Regular Air|           -54.0385|       7.3|         7.72|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Binders and Binde...|Angle-D Binders w...|        Small Box|               0.38|  40711.0|\n",
      "|  98.0|   613.0|   40711.0|          High|          22.0|           905.08|    0.09|   Regular Air|              127.7|     42.76|         6.22|      Carl Jackson| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Mobile Desk...|        Small Box|               null|  40712.0|\n",
      "| 103.0|   643.0|   40626.0|          High|          21.0|          2781.82|    0.07|   Express Air|            -695.26|    138.14|         35.0|    Monica Federle| Nunavut|Nunavut|       Corporate| Office Supplies|Storage & Organiz...|SAFCO Commercial ...|        Large Box|               null|  40627.0|\n",
      "| 107.0|   678.0|   40235.0|           Low|          44.0|           228.41|    0.07|   Regular Air|            -226.36|      4.98|         8.33|   Dorothy Badders| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|           Xerox 198|        Small Box|               0.38|  40235.0|\n",
      "| 127.0|   807.0|   40505.0|        Medium|          45.0|           196.85|    0.01|   Regular Air|            -166.85|      4.28|         6.18|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|               Paper|          Xerox 1980|        Small Box|                0.4|  40506.0|\n",
      "| 128.0|   807.0|   40505.0|        Medium|          32.0|           124.56|    0.04|   Regular Air|             -14.33|      3.95|          2.0|   Neola Schneider| Nunavut|Nunavut|     Home Office| Office Supplies|        Rubber Bands|Advantus Map Penn...|         Wrap Bag|               0.53|  40506.0|\n",
      "| 134.0|   868.0|   41068.0| Not Specified|          32.0|           716.84|     0.0|   Regular Air|             134.72|     21.78|         5.94|       Carlos Daly| Nunavut|Nunavut|     Home Office| Office Supplies|          Appliances|Holmes HEPA Air P...|       Medium Box|                0.5|  41069.0|\n",
      "| 135.0|   868.0|   41068.0| Not Specified|          31.0|          1474.33|    0.04|   Regular Air|             114.46|     47.98|         3.61|       Carlos Daly| Nunavut|Nunavut|     Home Office|      Technology|Computer Peripherals|DS/HD IBM Formatt...|       Small Pack|               0.71|  41070.0|\n",
      "| 149.0|   933.0|   41125.0| Not Specified|          15.0|            80.61|    0.02|   Regular Air|             -4.715|      5.28|         2.99|     Claudia Miner| Nunavut|Nunavut|  Small Business| Office Supplies|Binders and Binde...|Wilson Jones 1\" H...|        Small Box|               0.37|  41125.0|\n",
      "| 160.0|   995.0|   40693.0|        Medium|          46.0|          1815.49|    0.03|   Regular Air|             782.91|     39.89|         3.04|   Neola Schneider| Nunavut|Nunavut|     Home Office|       Furniture|  Office Furnishings|Ultra Commercial ...|         Wrap Bag|               0.53|  40694.0|\n",
      "| 161.0|   998.0|   40142.0| Not Specified|          16.0|           248.26|    0.07|   Regular Air|               93.8|     15.74|         1.39|  Allen Rosenblatt| Nunavut|Nunavut|  Small Business| Office Supplies|           Envelopes|#10-4 1/8\" x 9 1/...|        Small Box|                0.4|  40143.0|\n",
      "| 175.0|  1154.0|   40953.0|      Critical|          44.0|          4462.23|    0.04|Delivery Truck|             440.72|    100.98|        26.22|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|           Bookcases|Hon 4-Shelf Metal...|        Jumbo Box|                0.6|  40955.0|\n",
      "| 176.0|  1154.0|   40953.0|      Critical|          11.0|663.7840000000001|    0.25|   Regular Air|           -481.041|     71.37|         69.0|   Sylvia Foulston| Nunavut|Nunavut|     Home Office|       Furniture|              Tables|Lesro Sheffield C...|        Large Box|               0.68|  40955.0|\n",
      "| 203.0|  1344.0|   41014.0|           Low|          15.0|          834.904|    0.06|   Regular Air|-11.681999999999999|     65.99|         5.26|       Jim Radford| Nunavut|Nunavut|       Corporate|      Technology|Telephones and Co...|                g520|        Small Box|               0.59|  41021.0|\n",
      "+------+--------+----------+--------------+--------------+-----------------+--------+--------------+-------------------+----------+-------------+------------------+--------+-------+----------------+----------------+--------------------+--------------------+-----------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('dataset_to_view') #create a view\n",
    "output = spark.sql(\"select * from dataset_to_view\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381d8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-10-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# logic to convert unix times cast as doubles to datetime format\n",
    "import datetime\n",
    "serial = 40464.0\n",
    "seconds = (serial - 25569) * 86400.0\n",
    "print(datetime.datetime.utcfromtimestamp(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dcecfc4-9f2e-4949-8b02-0370192161c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|my_timestamp|order_date|\n",
      "+------------+----------+\n",
      "|  2010-10-13|   40464.0|\n",
      "|  2012-10-01|   41183.0|\n",
      "|  2012-10-01|   41183.0|\n",
      "|  2011-07-10|   40734.0|\n",
      "|  2010-08-28|   40418.0|\n",
      "|  2010-08-28|   40418.0|\n",
      "|  2011-06-17|   40711.0|\n",
      "|  2011-06-17|   40711.0|\n",
      "|  2011-03-24|   40626.0|\n",
      "|  2010-02-26|   40235.0|\n",
      "|  2010-11-23|   40505.0|\n",
      "|  2010-11-23|   40505.0|\n",
      "|  2012-06-08|   41068.0|\n",
      "|  2012-06-08|   41068.0|\n",
      "|  2012-08-04|   41125.0|\n",
      "|  2011-05-30|   40693.0|\n",
      "|  2009-11-25|   40142.0|\n",
      "|  2012-02-14|   40953.0|\n",
      "|  2012-02-14|   40953.0|\n",
      "|  2012-04-15|   41014.0|\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in spark SQL\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "from pyspark.sql.functions import * \n",
    "output = spark.sql(\"\"\"SELECT from_unixtime\n",
    "(\n",
    " (CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd'\n",
    ") \n",
    "AS my_timestamp,\n",
    "`Order Date` as order_date \n",
    "FROM dataset_to_view\n",
    "\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58a98512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|my_timestamp|order_date|\n",
      "+------------+----------+\n",
      "|  2010-10-13|   40464.0|\n",
      "|  2012-10-01|   41183.0|\n",
      "|  2012-10-01|   41183.0|\n",
      "|  2011-07-10|   40734.0|\n",
      "|  2010-08-28|   40418.0|\n",
      "|  2010-08-28|   40418.0|\n",
      "|  2011-06-17|   40711.0|\n",
      "|  2011-06-17|   40711.0|\n",
      "|  2011-03-24|   40626.0|\n",
      "|  2010-02-26|   40235.0|\n",
      "|  2010-11-23|   40505.0|\n",
      "|  2010-11-23|   40505.0|\n",
      "|  2012-06-08|   41068.0|\n",
      "|  2012-06-08|   41068.0|\n",
      "|  2012-08-04|   41125.0|\n",
      "|  2011-05-30|   40693.0|\n",
      "|  2009-11-25|   40142.0|\n",
      "|  2012-02-14|   40953.0|\n",
      "|  2012-02-14|   40953.0|\n",
      "|  2012-04-15|   41014.0|\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") # used to resolve date format issue\n",
    "from pyspark.sql.functions import * \n",
    "output = spark.sql(\"\"\"\n",
    "SELECT to_date(from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400)) AS my_timestamp,\n",
    "       `Order Date` as order_date \n",
    "FROM dataset_to_view\n",
    "\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e135973-4078-4781-84b1-d6f57c0e7f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Order Priority|count|\n",
      "+--------------+-----+\n",
      "|          High| 1768|\n",
      "|           Low| 1720|\n",
      "|        Medium| 1631|\n",
      "|      Critical| 1608|\n",
      "| Not Specified| 1672|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query to get count of  \"High\",\"low\",\"Medium\" and \"Not Specified\" values in Order Priority column.\n",
    "output =spark.sql(\"\"\"SELECT `Order Priority`, COUNT(*)  as count\n",
    "FROM dataset_to_view\n",
    "GROUP BY `Order Priority`\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23f842a-046c-4653-b22c-d02c2e94944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Order Priority|count|\n",
      "+--------------+-----+\n",
      "|      Critical| 1608|\n",
      "|          High| 1768|\n",
      "|           Low| 1720|\n",
      "|        Medium| 1631|\n",
      "| Not Specified| 1672|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query to get count of  \"High\",\"low\",\"Medium\" and \"Not Specified\" values in Order Priority column.\n",
    "output =spark.sql(\"\"\"select `Order Priority`, count from\n",
    "(SELECT `Order Priority`, COUNT(`Order Priority`) over (partition by `Order Priority`) as count,\n",
    "row_number() over (partition by `Order Priority` order by 1) as rn\n",
    "FROM dataset_to_view) where rn=1\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddb0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Row ID|         order_date|\n",
      "+------+-------------------+\n",
      "|  14.0|2010-12-17 05:30:00|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query to display latest 5 records per row_id with respect to Order Date.\n",
    "output =spark.sql(\"\"\"select * from (select `Row ID`, order_date from\n",
    "(SELECT `Row ID`, \n",
    "from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') AS order_date,\n",
    "rank() over \n",
    "(partition by `Row ID` \n",
    "order by from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') desc) as rn\n",
    "FROM dataset_to_view) where rn<6) where `Row ID`='14.0'\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74762134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|Order ID|count(Order ID)|\n",
      "+--------+---------------+\n",
      "| 18308.0|              3|\n",
      "| 58626.0|              3|\n",
      "| 39846.0|              2|\n",
      "| 16193.0|              2|\n",
      "| 24007.0|              3|\n",
      "| 53511.0|              2|\n",
      "|  9537.0|              2|\n",
      "| 24387.0|              2|\n",
      "| 30658.0|              2|\n",
      "| 24128.0|              2|\n",
      "| 24097.0|              3|\n",
      "| 26370.0|              2|\n",
      "| 29287.0|              2|\n",
      "| 31781.0|              2|\n",
      "| 10435.0|              2|\n",
      "| 21889.0|              2|\n",
      "| 12096.0|              2|\n",
      "| 43109.0|              3|\n",
      "| 32193.0|              2|\n",
      "|  1539.0|              2|\n",
      "+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------------+\n",
      "|Row ID|count(Row ID)|\n",
      "+------+-------------+\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output =spark.sql(\"\"\"select `Order ID`,count(`Order ID`)\n",
    "FROM dataset_to_view\n",
    "group by `Order ID` having count(`Order ID`)>1\n",
    "                    \"\"\")\n",
    "output.show()\n",
    "output =spark.sql(\"\"\"select `Row ID`,count(`Row ID`)\n",
    "FROM dataset_to_view\n",
    "group by `Row ID` having count(`Row ID`)>1\n",
    "                    \"\"\")\n",
    "output.show()\n",
    "# We can see that Row ID is having unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c414496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+\n",
      "|Row ID|Order ID|         order_date|\n",
      "+------+--------+-------------------+\n",
      "|3355.0| 24007.0|2010-08-26 05:30:00|\n",
      "|3356.0| 24007.0|2010-08-26 05:30:00|\n",
      "|3357.0| 24007.0|2010-08-26 05:30:00|\n",
      "+------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query to display latest 5 records per order_id with respect to Order Date.\n",
    "output =spark.sql(\"\"\"select * from (select `Row ID`,`Order ID`, order_date from\n",
    "(SELECT `Order ID`, `Row ID`,\n",
    "from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') AS order_date,\n",
    "rank() over \n",
    "(partition by `Order ID` \n",
    "order by from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') desc) as rn\n",
    "FROM dataset_to_view) where rn<6) where `Order ID`='24007.0'\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04095a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+--------------+\n",
      "|    Customer Name|         order_date|Order Quantity|\n",
      "+-----------------+-------------------+--------------+\n",
      "|       Sam Craven|2012-05-05 05:30:00|          50.0|\n",
      "|   David Philippe|2012-10-06 05:30:00|          50.0|\n",
      "| Mitch Willingham|2012-07-13 05:30:00|          50.0|\n",
      "|Jason Klamczynski|2012-08-10 05:30:00|          50.0|\n",
      "|   Jeremy Ellison|2012-10-29 05:30:00|          50.0|\n",
      "|    Harold Pawlan|2012-12-18 05:30:00|          50.0|\n",
      "|      Meg Tillman|2012-07-15 05:30:00|          50.0|\n",
      "|       Tony Sayre|2012-12-16 05:30:00|          50.0|\n",
      "|    Dave Hallsten|2012-12-02 05:30:00|          50.0|\n",
      "| Natalie Fritzler|2012-05-17 05:30:00|          50.0|\n",
      "|   Thea Hendricks|2012-05-29 05:30:00|          50.0|\n",
      "|     Dan Campbell|2012-08-13 05:30:00|          50.0|\n",
      "|Christine Abelman|2012-09-29 05:30:00|          50.0|\n",
      "|    Bobby Trafton|2012-07-19 05:30:00|          50.0|\n",
      "|    Brendan Murry|2012-09-02 05:30:00|          50.0|\n",
      "|  Laurel Elliston|2012-10-18 05:30:00|          50.0|\n",
      "|       Tony Sayre|2012-09-02 05:30:00|          50.0|\n",
      "|Matthew Grinstein|2012-10-28 05:30:00|          50.0|\n",
      "|  Penelope Sewall|2012-09-18 05:30:00|          50.0|\n",
      "|     Quincy Jones|2012-08-14 05:30:00|          50.0|\n",
      "+-----------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#top customers who have made the most orders in the last 11 years.\n",
    "output =spark.sql(\"\"\"select `Customer Name`,\n",
    "from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') AS order_date,\n",
    "`Order Quantity`\n",
    "FROM dataset_to_view\n",
    "where from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd HH:mm:ss') > current_date()-3960\n",
    "order by `Order Quantity` desc\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9f3d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------+--------------+\n",
      "|    Customer Name|order_date|Order Quantity|Order Priority|\n",
      "+-----------------+----------+--------------+--------------+\n",
      "|   Jeremy Ellison|2012-10-29|          50.0|      Critical|\n",
      "|       Tony Sayre|2012-12-16|          50.0|      Critical|\n",
      "|  Penelope Sewall|2012-09-18|          50.0|      Critical|\n",
      "|   Thea Hendricks|2012-05-29|          50.0|          High|\n",
      "|Matthew Grinstein|2012-10-28|          50.0|          High|\n",
      "|  Laura Armstrong|2012-08-22|          50.0|          High|\n",
      "| Natalie Fritzler|2012-05-17|          50.0|          High|\n",
      "|      Meg Tillman|2012-07-15|          50.0|          High|\n",
      "|    Harold Pawlan|2012-12-18|          50.0|          High|\n",
      "|    Hilary Holden|2012-08-11|          50.0|          High|\n",
      "|       Sam Craven|2012-05-05|          50.0|           Low|\n",
      "|    Brendan Murry|2012-09-02|          50.0|           Low|\n",
      "|       Tony Sayre|2012-09-02|          50.0|           Low|\n",
      "|       Roy Skaria|2012-06-27|          50.0|           Low|\n",
      "|Giulietta Baptist|2012-10-25|          50.0|           Low|\n",
      "|Christine Abelman|2012-09-29|          50.0|           Low|\n",
      "|Jason Klamczynski|2012-08-10|          50.0|           Low|\n",
      "|     Dan Campbell|2012-08-13|          50.0|        Medium|\n",
      "|     Nick Radford|2012-08-15|          50.0|        Medium|\n",
      "|   Arthur Prichep|2012-07-30|          50.0|        Medium|\n",
      "+-----------------+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As we can see most of them are having same order quantity lets consider Order Priority i.e., whose order priority is Critical-High\n",
    "output =spark.sql(\"\"\"select `Customer Name`,\n",
    "from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd') AS order_date,\n",
    "`Order Quantity`, `Order Priority`\n",
    "FROM dataset_to_view\n",
    "where from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd') > current_date()-3960\n",
    "order by `Order Quantity` desc, `Order Priority`\n",
    "                    \"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5451426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+--------------------+--------------------+----------------------------+\n",
      "|  Customer Name|Product category|Product Sub-Category|        Product Name|(Unit Price + Shipping Cost)|\n",
      "+---------------+----------------+--------------------+--------------------+----------------------------+\n",
      "|Jasper Cacioppo|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "|     Emily Phan|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "| Craig Carreira|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "|    Roger Demir|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "| Laurel Workman|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "|  Adrian Barton|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "|       Roy Phan|      Technology|     Office Machines|Polycom ViewStati...|                     6807.51|\n",
      "+---------------+----------------+--------------------+--------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the maximum cost(First Highest cost) : Unit Price + Shipping Cost\n",
    "output = spark.sql(\"\"\"\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost`\n",
    "    FROM dataset_to_view\n",
    "    WHERE (`Unit Price` + `Shipping Cost`) = (\n",
    "        SELECT MAX(`Unit Price` + `Shipping Cost`) \n",
    "        FROM dataset_to_view\n",
    "    )\n",
    "\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d18c7fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------------------+--------------------+----------------------------+\n",
      "|   Customer Name|Product category|Product Sub-Category|        Product Name|(Unit Price + Shipping Cost)|\n",
      "+----------------+----------------+--------------------+--------------------+----------------------------+\n",
      "|      Erica Bern|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|    Tony Chapman|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|  Parhena Norris|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|     Dennis Kane|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|    Nathan Mautz|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|Maxwell Schwartz|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "|     Cyra Reiten|      Technology|     Copiers and Fax|Canon imageCLASS ...|          3524.4799999999996|\n",
      "+----------------+----------------+--------------------+--------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the 2nd maximum cost(Second Highest cost) : Unit Price + Shipping Cost\n",
    "output = spark.sql(\"\"\"\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost`\n",
    "    FROM dataset_to_view\n",
    "    WHERE (`Unit Price` + `Shipping Cost`) = (\n",
    "        SELECT MAX(`Unit Price` + `Shipping Cost`) \n",
    "        FROM dataset_to_view\n",
    "        where (`Unit Price` + `Shipping Cost`) < (select MAX(`Unit Price` + `Shipping Cost`) from dataset_to_view)\n",
    "    )\n",
    "\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2480b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+--------------------+----------------------------+\n",
      "|     Customer Name|Product category|Product Sub-Category|        Product Name|(Unit Price + Shipping Cost)|\n",
      "+------------------+----------------+--------------------+--------------------+----------------------------+\n",
      "| Tamara Willingham|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "|      Irene Maddox|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "|     Juliana Krohn|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "|Lauren Leatherbury|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "|     Clay Cheatham|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "|    Alan Dominguez|      Technology|     Office Machines|Okidata Pacemark ...|                     3510.87|\n",
      "+------------------+----------------+--------------------+--------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the 3rd maximum cost(Third Highest cost) : Unit Price + Shipping Cost\n",
    "output = spark.sql(\"\"\"\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost`\n",
    "    FROM dataset_to_view\n",
    "    WHERE (`Unit Price` + `Shipping Cost`) = \n",
    "    (\n",
    "        SELECT MAX(`Unit Price` + `Shipping Cost`) FROM dataset_to_view \n",
    "        where (`Unit Price` + `Shipping Cost`) < \n",
    "        (select MAX(`Unit Price` + `Shipping Cost`) from dataset_to_view\n",
    "        where (`Unit Price` + `Shipping Cost`) < (select MAX(`Unit Price` + `Shipping Cost`) from dataset_to_view)\n",
    "    )\n",
    "    )\n",
    "\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca36e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "|     Customer Name|Product category|Product Sub-Category|        Product Name|       Total_Price| rn|\n",
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "|   Jasper Cacioppo|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|        Emily Phan|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|    Craig Carreira|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|       Roger Demir|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|    Laurel Workman|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|     Adrian Barton|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|          Roy Phan|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|        Erica Bern|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|      Tony Chapman|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|    Parhena Norris|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|       Dennis Kane|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|      Nathan Mautz|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|  Maxwell Schwartz|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "|       Cyra Reiten|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  8|\n",
      "| Tamara Willingham|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "|      Irene Maddox|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "|     Juliana Krohn|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "|Lauren Leatherbury|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "|     Clay Cheatham|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "|    Alan Dominguez|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87| 15|\n",
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the 3rd maximum cost(Third Highest cost) : Unit Price + Shipping Cost\n",
    "#Approach using Rank() vs Dense_rank()\n",
    "output = spark.sql(\"\"\"\n",
    "    select `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost` as Total_Price,\n",
    "           rn\n",
    "    from (\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price`,\n",
    "           `Shipping Cost`,\n",
    "           rank() over (order by (`Unit Price` + `Shipping Cost`) desc) rn\n",
    "    FROM dataset_to_view\n",
    "    ) temp\n",
    "    where rn<100\n",
    "\"\"\")\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae208bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "|     Customer Name|Product category|Product Sub-Category|        Product Name|       Total_Price| rn|\n",
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "|   Jasper Cacioppo|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|        Emily Phan|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|    Craig Carreira|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|       Roger Demir|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|    Laurel Workman|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|     Adrian Barton|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|          Roy Phan|      Technology|     Office Machines|Polycom ViewStati...|           6807.51|  1|\n",
      "|        Erica Bern|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|      Tony Chapman|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|    Parhena Norris|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|       Dennis Kane|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|      Nathan Mautz|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|  Maxwell Schwartz|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "|       Cyra Reiten|      Technology|     Copiers and Fax|Canon imageCLASS ...|3524.4799999999996|  2|\n",
      "| Tamara Willingham|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "|      Irene Maddox|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "|     Juliana Krohn|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "|Lauren Leatherbury|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "|     Clay Cheatham|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "|    Alan Dominguez|      Technology|     Office Machines|Okidata Pacemark ...|           3510.87|  3|\n",
      "+------------------+----------------+--------------------+--------------------+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the 3rd maximum cost(Third Highest cost) : Unit Price + Shipping Cost\n",
    "#Approach using Rank() vs Dense_rank()\n",
    "output = spark.sql(\"\"\"\n",
    "    select `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost` as Total_Price,\n",
    "           rn\n",
    "    from (\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price`,\n",
    "           `Shipping Cost`,\n",
    "           dense_rank() over (order by (`Unit Price` + `Shipping Cost`) desc) rn\n",
    "    FROM dataset_to_view\n",
    "    ) temp\n",
    "    where rn<100\n",
    "\"\"\")\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aee9c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+--------------------+-----------+\n",
      "|     Customer Name|Product category|Product Sub-Category|        Product Name|Total_Price|\n",
      "+------------------+----------------+--------------------+--------------------+-----------+\n",
      "| Tamara Willingham|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "|      Irene Maddox|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "|     Juliana Krohn|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "|Lauren Leatherbury|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "|     Clay Cheatham|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "|    Alan Dominguez|      Technology|     Office Machines|Okidata Pacemark ...|    3510.87|\n",
      "+------------------+----------------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which product has the 3rd maximum cost(Third Highest cost) : Unit Price + Shipping Cost\n",
    "#Approach using Rank() vs Dense_rank()\n",
    "output = spark.sql(\"\"\"\n",
    "    select `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price` + `Shipping Cost` as Total_Price\n",
    "           --rn\n",
    "    from (\n",
    "    SELECT `Customer Name`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           `Unit Price`,\n",
    "           `Shipping Cost`,\n",
    "           dense_rank() over (order by (`Unit Price` + `Shipping Cost`) desc) rn\n",
    "    FROM dataset_to_view\n",
    "    ) temp\n",
    "    where rn=3\n",
    "\"\"\")\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9d88267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-----------------+-----+\n",
      "|   Sales|Product category|        sum_sales|month|\n",
      "+--------+----------------+-----------------+-----+\n",
      "|14223.82|       Furniture|566363.4880000002|  Dec|\n",
      "|  291.66|       Furniture|566363.4880000002|  Dec|\n",
      "| 6641.14|       Furniture|566363.4880000002|  Dec|\n",
      "|10469.03|       Furniture|566363.4880000002|  Dec|\n",
      "| 1280.34|       Furniture|566363.4880000002|  Dec|\n",
      "|  145.68|       Furniture|566363.4880000002|  Dec|\n",
      "| 1270.03|       Furniture|566363.4880000002|  Dec|\n",
      "| 1773.86|       Furniture|566363.4880000002|  Dec|\n",
      "|  543.22|       Furniture|566363.4880000002|  Dec|\n",
      "|   813.9|       Furniture|566363.4880000002|  Dec|\n",
      "| 5016.25|       Furniture|566363.4880000002|  Dec|\n",
      "|  152.84|       Furniture|566363.4880000002|  Dec|\n",
      "|  549.92|       Furniture|566363.4880000002|  Dec|\n",
      "| 5572.92|       Furniture|566363.4880000002|  Dec|\n",
      "|10338.93|       Furniture|566363.4880000002|  Dec|\n",
      "|15897.01|       Furniture|566363.4880000002|  Dec|\n",
      "|   919.0|       Furniture|566363.4880000002|  Dec|\n",
      "| 2932.99|       Furniture|566363.4880000002|  Dec|\n",
      "|  9194.8|       Furniture|566363.4880000002|  Dec|\n",
      "| 2285.12|       Furniture|566363.4880000002|  Dec|\n",
      "+--------+----------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculates the running total of sales within each category, ordered by month\n",
    "output = spark.sql(\"\"\"\n",
    "    select `Sales`,\n",
    "           `Product category`, \n",
    "           sum_sales,\n",
    "           decode(substr(order_date,6,2),\n",
    "           '01','Jan',\n",
    "           '02','Feb',\n",
    "           '03','Mar',\n",
    "           '04','Apr',\n",
    "           '05','May',\n",
    "           '06','Jun',\n",
    "           '07','Jul',\n",
    "           '08','Aug',\n",
    "           '09','Sep',\n",
    "           '10','Oct',\n",
    "           '11','Nov',\n",
    "           '12','Dec',\n",
    "           'NA') as month\n",
    "    from (\n",
    "    SELECT `Sales`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd') as order_date,\n",
    "           sum(`Sales`) over (partition by `Product category` \n",
    "           order by (substr(from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd'),6,2)) desc) sum_sales\n",
    "    FROM dataset_to_view\n",
    "    ) temp\n",
    "\"\"\")\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e343949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-----------------+-----+\n",
      "|   Sales|Product category|        sum_sales|month|\n",
      "+--------+----------------+-----------------+-----+\n",
      "|  261.54| Office Supplies|3752762.099999994|  Oct|\n",
      "|  845.32| Office Supplies|3752762.099999994|  Jan|\n",
      "|10123.02| Office Supplies|3752762.099999994|  Oct|\n",
      "|  244.57| Office Supplies|3752762.099999994|  Oct|\n",
      "|  394.27| Office Supplies|3752762.099999994|  Aug|\n",
      "|   93.54| Office Supplies|3752762.099999994|  Jun|\n",
      "|  905.08| Office Supplies|3752762.099999994|  Jun|\n",
      "| 2781.82| Office Supplies|3752762.099999994|  Mar|\n",
      "|  228.41| Office Supplies|3752762.099999994|  Feb|\n",
      "|  196.85| Office Supplies|3752762.099999994|  Nov|\n",
      "|  124.56| Office Supplies|3752762.099999994|  Nov|\n",
      "|  716.84| Office Supplies|3752762.099999994|  Jun|\n",
      "|   80.61| Office Supplies|3752762.099999994|  Aug|\n",
      "|  248.26| Office Supplies|3752762.099999994|  Nov|\n",
      "|   59.03| Office Supplies|3752762.099999994|  Mar|\n",
      "|   97.48| Office Supplies|3752762.099999994|  Mar|\n",
      "|  511.83| Office Supplies|3752762.099999994|  Mar|\n",
      "|    80.9| Office Supplies|3752762.099999994|  Aug|\n",
      "|   67.24| Office Supplies|3752762.099999994|  May|\n",
      "|  370.48| Office Supplies|3752762.099999994|  Nov|\n",
      "+--------+----------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculates the total sales for each category across all months\n",
    "output = spark.sql(\"\"\"select * from (SELECT `Sales`,\n",
    "       `Product category`, \n",
    "       sum_sales,\n",
    "       decode(substr(order_date,6,2),\n",
    "              '01','Jan',\n",
    "              '02','Feb',\n",
    "              '03','Mar',\n",
    "              '04','Apr',\n",
    "              '05','May',\n",
    "              '06','Jun',\n",
    "              '07','Jul',\n",
    "              '08','Aug',\n",
    "              '09','Sep',\n",
    "              '10','Oct',\n",
    "              '11','Nov',\n",
    "              '12','Dec',\n",
    "              'NA') as month\n",
    "FROM (\n",
    "    SELECT `Sales`,\n",
    "           `Product category`, \n",
    "           `Product Sub-Category`,\n",
    "           `Product Name`,\n",
    "           from_unixtime((CAST(dataset_to_view.`Order Date` AS DOUBLE) - 25569) * 86400,'yyyy-MM-dd') as order_date,\n",
    "           sum(`Sales`) over (partition by `Product category`) as sum_sales\n",
    "    FROM dataset_to_view\n",
    ") )order by sum_sales\n",
    "\"\"\")\n",
    "\n",
    "output.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "805ddb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+--------------+--------------+-----+--------+---------+------+----------+-------------+-------------+--------+------+----------------+----------------+--------------------+------------+-----------------+-------------------+---------+\n",
      "|Row ID|Order ID|Order Date|Order Priority|Order Quantity|Sales|Discount|Ship Mode|Profit|Unit Price|Shipping Cost|Customer Name|Province|Region|Customer Segment|Product Category|Product Sub-Category|Product Name|Product Container|Product Base Margin|Ship Date|\n",
      "+------+--------+----------+--------------+--------------+-----+--------+---------+------+----------+-------------+-------------+--------+------+----------------+----------------+--------------------+------------+-----------------+-------------------+---------+\n",
      "+------+--------+----------+--------------+--------------+-----+--------+---------+------+----------+-------------+-------------+--------+------+----------------+----------------+--------------------+------------+-----------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To display all duplicate records if any\n",
    "output = spark.sql('''\n",
    "select vo.* \n",
    "from dataset_to_view vo \n",
    "where `Row ID` <> (select max(vi.`Row ID`) from dataset_to_view vi where vo.`Row ID`=vi.`Row ID` )\n",
    "''')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d449fac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+------------------+\n",
      "|        Product Name|order_month|         order_date|            Profit|\n",
      "+--------------------+-----------+-------------------+------------------+\n",
      "|Polycom ViaVideo...|         01|2009-01-03 05:30:00|          14440.39|\n",
      "|Hewlett-Packard c...|         02|2009-02-05 05:30:00|           8734.88|\n",
      "|Polycom ViewStati...|         03|2009-03-21 05:30:00|          27220.69|\n",
      "|Hewlett Packard L...|         04|2011-04-30 05:30:00|          9097.645|\n",
      "|Polycom ViewStati...|         05|2012-05-04 05:30:00|           6138.48|\n",
      "|Fellowes PB500 El...|         06|2009-06-07 05:30:00|10951.306499999999|\n",
      "|Hewlett-Packard B...|         07|2009-07-31 05:30:00|          12606.81|\n",
      "|Epson LQ-870 Dot ...|         08|2012-08-07 05:30:00|           7080.99|\n",
      "|Hewlett Packard L...|         09|2010-09-29 05:30:00| 9791.041000000001|\n",
      "|Fellowes PB500 El...|         10|2009-10-04 05:30:00|         11535.282|\n",
      "|Hewlett-Packard c...|         11|2012-11-19 05:30:00|          10521.33|\n",
      "|Hewlett Packard L...|         12|2009-12-30 05:30:00|         11630.146|\n",
      "+--------------------+-----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get hihgest profit per month\n",
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "output = spark.sql('''\n",
    "select `Product Name`,\n",
    "order_month,\n",
    "order_date,\n",
    "Profit\n",
    "from\n",
    "(SELECT \n",
    "  `Product Name`,\n",
    "  substr(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400)),6,2) AS order_month,\n",
    "  from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400)) as order_date,\n",
    "  row_number() OVER (partition BY substr(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400)),6,2) order by Profit desc) AS max_profit,\n",
    "  Profit\n",
    "FROM dataset_to_view) \n",
    "where max_profit=1\n",
    "''')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97027fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|        Product Name|order_month|        total_profit|\n",
      "+--------------------+-----------+--------------------+\n",
      "|\"While you Were O...|         01|                8.33|\n",
      "|\"While you Were O...|         05|               14.13|\n",
      "|\"While you Were O...|         06|               -0.31|\n",
      "|\"While you Were O...|         12|-0.12000000000000055|\n",
      "|\"While you Were O...|         12|-0.12000000000000055|\n",
      "|#10 Self-Seal Whi...|         05|               21.71|\n",
      "|#10 Self-Seal Whi...|         05|               21.71|\n",
      "|#10 Self-Seal Whi...|         08|               52.27|\n",
      "|#10 Self-Seal Whi...|         11|               27.55|\n",
      "|#10 Self-Seal Whi...|         12|                39.0|\n",
      "|#10 White Busines...|         04|   561.8499999999999|\n",
      "|#10 White Busines...|         04|   561.8499999999999|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         06|              838.32|\n",
      "|#10 White Busines...|         06|              838.32|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using User defined function in spark SQL\n",
    "#import datetime\n",
    "#import pytz\n",
    "#import threading\n",
    "#import multiprocessing\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "\n",
    "def process_data():\n",
    "    # Define date parser function and register UDF\n",
    "    def dateParser(date_input,specifier,date_format):\n",
    "        if(date_format=='YYYY-MM-DD' or date_format=='YYYY/MM/DD'):\n",
    "            if(specifier=='month'):\n",
    "                return date_input[5:7]\n",
    "            elif(specifier=='day'):\n",
    "                return date_input[8:10]\n",
    "            elif(specifier=='year'):\n",
    "                return date_input[0:4]\n",
    "            else:\n",
    "                return \"wrong specifier mentioned\"\n",
    "        elif(date_format=='DD-MM-YYYY' or date_format=='DD/MM/YYYY'):\n",
    "            if(specifier=='month'):\n",
    "                return date_input[3:5]\n",
    "            elif(specifier=='day'):\n",
    "                return date_input[0:2]\n",
    "            elif(specifier=='year'):\n",
    "                return date_input[6:10]\n",
    "            else:\n",
    "                return \"wrong specifier mentioned\"\n",
    "        else:\n",
    "            return \"wrong date format specified\"\n",
    "\n",
    "    def dateParserWrapper(date_input,specifier,date_format):\n",
    "        return dateParser(date_input,specifier,date_format)\n",
    "\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import StringType\n",
    "    \n",
    "    # converting python function to spark UDF (user defined function)\n",
    "    udf_dateParser = udf(dateParserWrapper, StringType())\n",
    "    \n",
    "    # Registering the function in spark to use in spark SQL\n",
    "    spark.udf.register(\"udf_dateParser\", udf_dateParser)\n",
    "\n",
    "    # Use the UDF to process the data\n",
    "    output = spark.sql('''\n",
    "        SELECT `Product Name`,\n",
    "           udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') AS order_month,\n",
    "           SUM(Profit) OVER(PARTITION BY `Product Name`, udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD')) AS total_profit\n",
    "    FROM dataset_to_view\n",
    "    order BY `Product Name`, udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD')\n",
    "    ''')\n",
    "    output.show()\n",
    "\n",
    "process_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55b704c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|        Product Name|order_month|        total_profit|\n",
      "+--------------------+-----------+--------------------+\n",
      "|\"While you Were O...|         01|                8.33|\n",
      "|\"While you Were O...|         05|               14.13|\n",
      "|\"While you Were O...|         06|               -0.31|\n",
      "|\"While you Were O...|         12|-0.12000000000000055|\n",
      "|#10 Self-Seal Whi...|         05|               21.71|\n",
      "|#10 Self-Seal Whi...|         08|               52.27|\n",
      "|#10 Self-Seal Whi...|         11|               27.55|\n",
      "|#10 Self-Seal Whi...|         12|                39.0|\n",
      "|#10 White Busines...|         04|   561.8499999999999|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         06|              838.32|\n",
      "|#10 White Busines...|         07|                9.35|\n",
      "|#10 White Busines...|         10|                12.5|\n",
      "|#10- 4 1/8\" x 9 1...|         01|               111.4|\n",
      "|#10- 4 1/8\" x 9 1...|         02|                10.8|\n",
      "|#10- 4 1/8\" x 9 1...|         03|             -384.77|\n",
      "|#10- 4 1/8\" x 9 1...|         05| -115.38000000000002|\n",
      "|#10- 4 1/8\" x 9 1...|         06|             -142.74|\n",
      "|#10- 4 1/8\" x 9 1...|         09| -117.03999999999999|\n",
      "|#10- 4 1/8\" x 9 1...|         10|             -239.51|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "When we use sum() over partition by clause, it will compute the sum of profit for each product and month combination \n",
    "separately and return a separate row for each combination. So, we may get multiple rows for the same product and month.\n",
    "If we want to get a single row per product per month, we can try using the group by clause along with sum() \n",
    "aggregate function instead of using sum() over partition by clause.\n",
    "'''\n",
    "output = spark.sql('''\n",
    "    select `Product Name`,\n",
    "    udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') as order_month,\n",
    "    sum(Profit) as total_profit\n",
    "    from dataset_to_view\n",
    "    group by `Product Name`, order_month\n",
    "    order by `Product Name`, udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') \n",
    "''')\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f4ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+-------+\n",
      "|        Product Name|order_month|      total_profit|row_num|\n",
      "+--------------------+-----------+------------------+-------+\n",
      "|Global Troy Exec...|         01|          23685.02|      1|\n",
      "|Okidata ML390 Tur...|         02|          13008.59|      1|\n",
      "|GBC DocuBind 200 ...|         03|         15381.991|      1|\n",
      "|Hewlett-Packard D...|         04|          18439.68|      1|\n",
      "|Polycom ViewStati...|         05|           6138.48|      1|\n",
      "|Fellowes PB500 El...|         06|10951.306499999999|      1|\n",
      "|Hewlett-Packard B...|         07|          24168.89|      1|\n",
      "|Riverside Palais ...|         08|           8573.84|      1|\n",
      "|Hewlett Packard L...|         09| 9791.041000000001|      1|\n",
      "|Canon PC1080F Per...|         10|         15991.267|      1|\n",
      "|Hewlett-Packard c...|         11|          18240.54|      1|\n",
      "|Global Troy Exec...|         12|14924.029999999999|      1|\n",
      "+--------------------+-----------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To check which Product is having max total_profit for that month\n",
    "output = spark.sql('''\n",
    "  select * from (\n",
    "  select t.*,\n",
    "  row_number() over (partition by t.order_month order by t.total_profit desc) row_num\n",
    "  from \n",
    "  (\n",
    "   select `Product Name`,\n",
    "    udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') as order_month,\n",
    "    sum(Profit) as total_profit\n",
    "    from dataset_to_view\n",
    "    group by `Product Name`, order_month\n",
    "    ) t\n",
    "    )\n",
    "    where row_num=1\n",
    "''')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aaa3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|        Product Name|order_month|        total_profit|\n",
      "+--------------------+-----------+--------------------+\n",
      "|\"While you Were O...|         01|                8.33|\n",
      "|\"While you Were O...|         05|               14.13|\n",
      "|\"While you Were O...|         06|               -0.31|\n",
      "|\"While you Were O...|         12|-0.12000000000000055|\n",
      "|#10 Self-Seal Whi...|         05|               21.71|\n",
      "|#10 Self-Seal Whi...|         08|               52.27|\n",
      "|#10 Self-Seal Whi...|         11|               27.55|\n",
      "|#10 Self-Seal Whi...|         12|                39.0|\n",
      "|#10 White Busines...|         04|   561.8499999999999|\n",
      "|#10 White Busines...|         05|             1428.78|\n",
      "|#10 White Busines...|         06|              838.32|\n",
      "|#10 White Busines...|         07|                9.35|\n",
      "|#10 White Busines...|         10|                12.5|\n",
      "|#10- 4 1/8\" x 9 1...|         01|               111.4|\n",
      "|#10- 4 1/8\" x 9 1...|         02|                10.8|\n",
      "|#10- 4 1/8\" x 9 1...|         03|             -384.77|\n",
      "|#10- 4 1/8\" x 9 1...|         05| -115.38000000000002|\n",
      "|#10- 4 1/8\" x 9 1...|         06|             -142.74|\n",
      "|#10- 4 1/8\" x 9 1...|         09| -117.03999999999999|\n",
      "|#10- 4 1/8\" x 9 1...|         10|             -239.51|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = spark.sql('''\n",
    "    select `Product Name`,\n",
    "    udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') as order_month,\n",
    "    sum(Profit) as total_profit\n",
    "    from dataset_to_view\n",
    "    group by `Product Name`, order_month\n",
    "    order by `Product Name`, udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400),'YYYY-MM-DD'),'month','YYYY-MM-DD') \n",
    "''')\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6698c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+------+\n",
      "|tot_orderquantity|order_day|rownum|\n",
      "+-----------------+---------+------+\n",
      "|           8204.0|       20|     1|\n",
      "+-----------------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which day of the month is having highest orders\n",
    "from pyspark.sql.functions import *\n",
    "output = spark.sql('''\n",
    "    select * from (\n",
    "    select sum(`Order Quantity`) as tot_orderquantity,\n",
    "    udf_dateParser(from_unixtime(((CAST(`Order Date` AS DOUBLE)-25569)*86400)),'day','YYYY-MM-DD') as order_day,\n",
    "    row_number() over (order by sum(`Order Quantity`) desc) rownum\n",
    "    from dataset_to_view\n",
    "    group by order_day\n",
    "    ) where rownum=1\n",
    "''')\n",
    "\n",
    "output.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c46885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
